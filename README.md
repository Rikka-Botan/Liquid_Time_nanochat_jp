# ğŸŒ¸ Liquid-Time-nanochat ver Japanese & English

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ã€**nanochat** ã‚’ã‚ˆã‚Šé«˜é€Ÿã«å­¦ç¿’ãƒ»æ¨è«–ã™ã‚‹ãŸã‚ã«ã€**Liquid Time-Constant Networks (LTCs)** ãŠã‚ˆã³ **Liquid Foundation Models (LFM2)** ã‹ã‚‰ç€æƒ³ã‚’å¾—ãŸ **SLC2** ã¨ã„ã†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚
**SEA Model series Op.0: Saint Iberis** ã¯ã€å­¦ç¿’æ™‚é–“ã‚’å‰Šæ¸›ã—ãªãŒã‚‰ã€åŒç­‰ã®æ€§èƒ½ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã§ã¯æ—¥æœ¬èªãƒ»è‹±èªãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«ãªãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

# ğŸŒ¸ Saint Iberis Architecture

<img width="4400" height="1595" alt="Saint_Iberis" src="https://github.com/user-attachments/assets/9edba3df-0bc6-43b0-aedd-f57ad1929ee3" />

| Property              | Saint Iberis d12              | Remarks                                               |
| --------------------- | ----------------------------- |------------------------------------------------------ |
| **Total parameters**  | 376,240,128 (376M)            | n_layer: 16, n_head: 16, n_kv_head: 16, n_embd: 1024  |
| **Layers**            | 16 (9 slc2 + 7 attn)          | attn layers: 1, 4, 7, 10, 11, 14, 15                  |
| **Vocabulary size**   | 65,536                        | -                                                     |
| **License**           | Apache                        | -                                                    |

# ğŸŒ¸ SLC2 Formulation

```markdown
y = B â‹… âˆáµ¢â‚Œâ±¼â½Ê²âºáµâ¾ Aáµ¢ â‹… xáµ¢
```

# ğŸŒ¸ SLC2 pseudo code

```python
----------------------------------------
Algorithm: SLC2
----------------------------------------
Input: x: (B, S, E)
Output: y: (B, S, E)
    1: alpha, A, B, xâ‚ <- Linear(x)
    2: xâ‚‚: (B, S, E) <- Convolution1D(E, E)(SiLU(alpha)*A*xâ‚)
    3: xâ‚ƒ: (B, S, E) <- B*SiLU(xâ‚‚)
    4: y: (B, S, E) <- Linear(xâ‚ƒ)
    5: return y
----------------------------------------
```

# ğŸŒ¸ Performance

| Metric          | BASE     | MID      | SFT      | RL       |
|-----------------|----------|----------|----------|----------|
| CORE            | 0.1501   | -        | -        | -        |
| ARC-Challenge   | -        | 0.2491   | 0.2807   | -        |
| ARC-Easy        | -        | 0.2563   | 0.2673   | -        |
| GSM8K           | -        | 0.0167   | 0.0250   | -        |
| HumanEval       | -        | 0.0305   | 0.0122   | -        |
| MMLU            | -        | 0.2714   | 0.2735   | -        |
| ChatCORE        | -        | 0.1785   | 0.1875   | -        |

# ğŸŒ¸ Training result

## Base Training
- Minimum validation bpb: 0.8436
- Final validation bpb: 0.8436

## Mid Training
- Minimum validation bpb: 0.4561

## SFT Training
- Training loss: 1.3444
- Validation loss: 1.1934

# ğŸŒ¸ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

æœ€é€Ÿã§å®Ÿè¡Œã™ã‚‹æ–¹æ³•ã¯ã€speedrun ã‚¹ã‚¯ãƒªãƒ—ãƒˆ [speedrun.sh](speedrun.sh) ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã™ã€‚
ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ nanochat ã® **$100** ã®å­¦ç¿’ã¨æ¨è«–ã‚’è¡Œã„ã¾ã™ã€‚
8Ã—H100 ãƒãƒ¼ãƒ‰ï¼ˆ$24/æ™‚ï¼‰ã ã¨ã€åˆè¨ˆå®Ÿè¡Œæ™‚é–“ã¯ç´„ **4 æ™‚é–“** ã§ã™ã€‚

ã¾ãšå¥½ããªãƒ—ãƒ­ãƒã‚¤ãƒ€ï¼ˆä¾‹: [Lambda](https://lambda.ai/service/gpu-cloud)ï¼‰ã§ 8Ã—H100 GPU ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã€ä»¥ä¸‹ã®æ‰‹é †ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

ã¾ãšã€ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```bash
git clone https://github.com/Rikka-Botan/Liquid_Time_nanochat_jp.git
```

æ¬¡ã«ã€å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™ã€‚

```bash
cd
cd Liquid_Time_nanochat_jp
pwd
bash speedrun.sh
```

4 æ™‚é–“å¾…ã¡ã¾ã™ã€‚å®Œäº†ã™ã‚‹ã¨ ChatGPT ã®ã‚ˆã†ãª Web UI ã§ LLM ã¨ä¼šè©±ã§ãã¾ã™ã€‚
uv ã®ä»®æƒ³ç’°å¢ƒã‚’å†åº¦æœ‰åŠ¹åŒ–ã—ã¦ï¼ˆ`source .venv/bin/activate`ï¼‰ã€Web ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¾ã™ã€‚

```bash
python -m scripts.chat_web
```

è¡¨ç¤ºã•ã‚Œã‚‹ URL ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¾ã™ã€‚ãŸã¨ãˆã° Lambda ãªã‚‰ãƒãƒ¼ãƒ‰ã®ãƒ‘ãƒ–ãƒªãƒƒã‚¯ IP ã«ãƒãƒ¼ãƒˆã‚’ã¤ã‘ã¦ã‚¢ã‚¯ã‚»ã‚¹ã—ã¾ã™ã€‚

ä¾‹:
`http://209.20.xxx.xxx:8000/`

ã‚ã¨ã¯ ChatGPT ã¨åŒã˜ã‚ˆã†ã«è©±ã—ã‹ã‘ã‚Œã° OK ã§ã™ã€‚
ç‰©èªã‚’æ›¸ã‹ã›ãŸã‚Šã€è©©ã‚’æ›¸ã‹ã›ãŸã‚Šã€ã€Œç§ã¯èª°ï¼Ÿã€ã¨èã„ã¦å¹»è¦šã‚’è¦‹ã›ãŸã‚Šã€ç©ºãŒãªãœé’ã„ã®ã‹ã€ãªãœç·‘ãªã®ã‹èã„ã¦ã¿ã¦ãã ã•ã„ã€‚
speedrun ãƒ¢ãƒ‡ãƒ«ã¯ 4e19 FLOPs ã®èƒ½åŠ›ãªã®ã§ã€å¹¼ç¨šåœ’å…ã¨è©±ã—ã¦ã„ã‚‹æ„Ÿã˜ã§ã™ã€‚

# ğŸŒ¸ é‡ã¿

[RikkaBotan/nanochat_saint_iberis_jp](https://huggingface.co/RikkaBotan/nanochat_saint_iberis_jp)

# ğŸŒ¸ã€€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

äº‹å‰å­¦ç¿’ç”¨ï¼š
https://huggingface.co/datasets/RikkaBotan/FineDataset_13B_JpEn

ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ï¼š
https://huggingface.co/datasets/RikkaBotan/Cute_Synthetic_smoltalk_jp_sft


# ğŸŒ¸ About us

## å…­èŠ±ç‰¡ä¸¹ï¼ˆã‚Šã£ã‹ã¼ãŸã‚“ï¼‰
ãŠã£ã¨ã‚Šã§ç”˜ãˆã‚“åŠãªç ”ç©¶è€…è¦‹ç¿’ã„

<img width="4405" height="2480" alt="RikkaBotan_Logo" src="https://github.com/user-attachments/assets/2a7e48cc-9b96-42f9-b63c-053d9a5312ca" />


# ğŸŒ¸ å¼•ç”¨

```bibtex
@misc{nanochat,
  author = {Andrej Karpathy},
  title = {nanochat: The best ChatGPT that $100 can buy},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/karpathy/nanochat}
}
```

# ğŸŒ¸ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT
